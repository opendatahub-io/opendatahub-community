# AI Explainability Working Group

A Working Group dedicated to establishing (designing, developing and documenting) an explainability framework for ODH developers (based on TrustyAI explainability toolkit). 
Explanations are useful tools in order to:
Establish trust in predictive models created / used in ODH, especially when deployed in decision making pipelines, e.g. provide explanations together with predictions to end users to allow humans to take better informed decisions
Debug predictions made by predictive models created / used in ODH, e.g. detect (portions of) model input that are responsible for counterintuitive predictions
Get a global understanding of general behavior of predictive models, e.g. which features does a model mostly attend to?

## Stakeholder SIGs
* [SIG ML Developer Experience](/sig-ml-developer-experience)
* [SIG ML Ops](/sig-ml-ops)

## Expected WG lifetime
6 months

## Meetings
* Working Group Meeting: TBD
  * [Meeting notes and Agenda] TBD.

## Organizers

* Rebecca Whitworth
* Tommaso Teofilli
* Rui Viera
* Rob Geada

## Contact
- Slack: [#wg-ai-explainabilityt-framework](https://odh-io.slack.com/archives/C03UFCVFFEY)
- [Mailing list] TBD
- [Open Community Issues/PRs] TBD

## Goals

* Establish a framework for the inclusion of explainability algorithms/capabilities in the Open Data Hub ecosystem in a cohesive and unified manner.
* Provide tools to ODH developers for explaining predictions made by predictive models.
* Provide tools to ODH developers for global model explainability. 

## Deliverables

* Provide TrustyAI-enabled JupiterHub extension for ODH. 
* Implement a _local_ explainability visualization.
* Implement a _global_ explainability visualization.

## Useful references

### TrustyAI Github Repositories

* [trustyai-explainability](https://github.com/trustyai-explainability/trustyai-explainability)
* [trustyai-explainability-python](https://github.com/trustyai-explainability/trustyai-explainability-python)
* [trustyai-explainability-python-examples](https://github.com/trustyai-explainability/trustyai-explainability-python-examples)

### TrustyAI technical documentation, tutorials and videos

* [TrustyAI Python Tutorial](https://trustyai-explainability-python.readthedocs.io/en/latest/tutorial.html#tutorial)
* [TrustyAI Blog](https://blog.kie.org/category/all?s=trustyai)
* [An introduction to Explainable AI](https://www.youtube.com/watch?v=mg_4UvQzC3w)
* [KIELive#51 - TrustyAI: Ensuring the Fairness and Transparency of Decision Models](https://www.youtube.com/watch?v=C5NGczQMHu0)
* [Shapley Additive Explanations (SHAP)](https://www.youtube.com/watch?v=VB9uV-x0gtg)
* [Introduction to Counterfactuals and how it helps understanding black-box prediction models](https://www.youtube.com/watch?v=zXwbzo_GcwA)
* [Explanation by Example: the OptaPlanner way](https://www.youtube.com/watch?v=4H3U6xyCgMI)
* [TrustyAI Drools Integration](https://drive.google.com/file/d/1Ti8HOzKUIJw7Qzp7J4jHEB0uYUd6lhYs/view)
* [TrustyAI Explainability Toolkit paper](https://arxiv.org/abs/2104.12717)


